{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the cv2 lib\n",
    "import cv2\n",
    "\n",
    "# OS traversal \n",
    "import os \n",
    "\n",
    "# Predicting \n",
    "from tqdm import tqdm \n",
    "\n",
    "# Array math \n",
    "import numpy as np \n",
    "\n",
    "# Ploting \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing the NAS vision model \n",
    "import super_gradients.training.models\n",
    "\n",
    "# Getting the sg model \n",
    "yolo_nas = super_gradients.training.models.get(\"yolo_nas_l\", pretrained_weights=\"coco\")\n",
    "\n",
    "# Defining the video name \n",
    "video_name = 'DJI_0763.MP4'\n",
    "\n",
    "# Defining the path to model and video dirs \n",
    "video_path = os.path.join(os.getcwd(), 'videos', video_name)\n",
    "\n",
    "# Defining the directory for extracted images \n",
    "extracted_images_dir = os.path.join(os.getcwd(), 'extracted_images')\n",
    "if not os.path.exists(extracted_images_dir):\n",
    "    os.mkdir(extracted_images_dir)\n",
    "\n",
    "# Postprocessed images \n",
    "postprocessed_images_dir = os.path.join(os.getcwd(), 'postprocessed_images')\n",
    "if not os.path.exists(postprocessed_images_dir):\n",
    "    os.mkdir(postprocessed_images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the video into images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_img = True\n",
    "\n",
    "if split_img:\n",
    "    # Reading the video \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Removing any image that is present in the extracted images dir\n",
    "    for image in os.listdir(extracted_images_dir):\n",
    "        os.remove(os.path.join(extracted_images_dir, image))\n",
    "\n",
    "    # Spliting the video by frame \n",
    "    i = 0\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        cv2.imwrite(os.path.join(extracted_images_dir, f'{str(i)}.jpg'), frame)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blurring the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the images in the extracted images dir\n",
    "images = os.listdir(extracted_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterbox(im, new_shape=(960, 960), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, r, (dw, dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example image pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting one image path \n",
    "image_path = os.path.join(extracted_images_dir, '2204.jpg')\n",
    "\n",
    "# Reading the image from open cv \n",
    "image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Saving the original image's w and h \n",
    "original_w, original_h = image.shape[1], image.shape[0]\n",
    "\n",
    "# Ploting the image \n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat = yolo_nas.predict(image)\n",
    "\n",
    "# Saving the list of class names\n",
    "class_names = hat[0].class_names \n",
    "\n",
    "# Making a dictionary where the key is the index and the value is the class name\n",
    "class_names_dict = {i: class_names[i] for i in range(len(class_names))}\n",
    "\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "\n",
    "# Extracting the predictions \n",
    "predictions = hat[0].prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the bboxes \n",
    "bboxes = predictions.bboxes_xyxy\n",
    "\n",
    "# Saving the labels \n",
    "labels = predictions.labels\n",
    "\n",
    "# Saving hte confidences\n",
    "confidences = predictions.confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over the bboxes\n",
    "if len(bboxes) > 0:\n",
    "    # Reading and plotting the original image\n",
    "    img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Iterating over the boxes\n",
    "    for i, box in enumerate(bboxes):\n",
    "        # Getting the class name\n",
    "        class_name = class_names_dict[labels[i]]\n",
    "\n",
    "        # Getting the x, y, w, h\n",
    "        x0, y0, x1, y1 = box[0], box[1], box[2], box[3]\n",
    "\n",
    "        # Converting to int\n",
    "        x0, y0, x1, y1 = int(x0), int(y0), int(x1), int(y1)\n",
    "\n",
    "        # Getting the confidence\n",
    "        confidence = round(float(confidences[i]), 2)\n",
    "\n",
    "        # Drawing the rectangle\n",
    "        cv2.rectangle(img, (x0, y0), (x1, y1), (0, 255, 0), 2)\n",
    "\n",
    "        # Putting the class name\n",
    "        cv2.putText(img, f\"{class_name} {confidence}\", (x0, y0 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "# Plotting the image\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying on all images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_blur = ['person']\n",
    "classes_to_draw = ['person', 'car', 'bus', 'truck']\n",
    "\n",
    "# Defining the number of frames to predict\n",
    "n_frames = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the images in the extracted images dir\n",
    "images = os.listdir(extracted_images_dir)\n",
    "\n",
    "# Creating the image dictionary where the key is the image name and the image index \n",
    "image_dict = dict()\n",
    "for image in images:\n",
    "    image_dict[image] = int(image.split('.')[0])\n",
    "\n",
    "# Sorting the images by the index\n",
    "images = sorted(images, key=lambda x: image_dict[x])\n",
    "\n",
    "# Removing the images that are not in the range\n",
    "if n_frames is not None:\n",
    "    images = images[:n_frames]\n",
    "\n",
    "# Iterating over the images\n",
    "list_of_images = []\n",
    "for image in tqdm(images):\n",
    "    # Predicting the bounding boxes\n",
    "    img = cv2.imread(os.path.join(extracted_images_dir, image))\n",
    "\n",
    "    # Making the prediction \n",
    "    hat = yolo_nas.predict(os.path.join(extracted_images_dir, image))\n",
    "\n",
    "    # Extracting the predictions\n",
    "    predictions = hat[0].prediction\n",
    "\n",
    "    # Saving the bboxes \n",
    "    bboxes = predictions.bboxes_xyxy\n",
    "\n",
    "    # Saving the labels \n",
    "    labels = predictions.labels\n",
    "\n",
    "    # Saving hte confidences\n",
    "    confidences = predictions.confidence\n",
    "\n",
    "    # Getting the bounding boxes\n",
    "    if len(bboxes) > 0:\n",
    "        # Iterating over the boxes\n",
    "        for i, box in enumerate(bboxes):\n",
    "            try:\n",
    "                # Getting the class name\n",
    "                class_name = class_names_dict[labels[i]]\n",
    "\n",
    "                if class_name in classes_to_draw:\n",
    "\n",
    "                    # Getting the x, y, w, h\n",
    "                    x0, y0, x1, y1 = box[0], box[1], box[2], box[3]\n",
    "\n",
    "                    # Converting to int\n",
    "                    x0, y0, x1, y1 = int(x0), int(y0), int(x1), int(y1)\n",
    "\n",
    "                    # Getting the confidence\n",
    "                    confidence = round(float(confidences[i]), 2)\n",
    "\n",
    "                    # Drawing the rectangle\n",
    "                    cv2.rectangle(img, (x0, y0), (x1, y1), (0, 255, 0), 2)\n",
    "\n",
    "                    # Putting the class name\n",
    "                    cv2.putText(img, f\"{class_name} {confidence}\", (x0, y0 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "                    if class_name in classes_to_blur:\n",
    "                        # Blurring the image\n",
    "                        img[y0:y1, x0:x1] = cv2.blur(img[y0:y1, x0:x1], (30, 30))\n",
    "            except Exception as e:\n",
    "                print(f\"{image} - {e}\")\n",
    "                continue\n",
    "\n",
    "    # Defining the path to the image\n",
    "    image_path = os.path.join(postprocessed_images_dir, os.path.basename(image))\n",
    "\n",
    "    # If the image exists in the postprocessed images dir, remove it\n",
    "    if os.path.exists(image_path):\n",
    "        os.remove(image_path)\n",
    "\n",
    "    # Saving the image\n",
    "    cv2.imwrite(image_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a video from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all the images in the postprocessed images dir to a video\n",
    "images = os.listdir(postprocessed_images_dir)\n",
    "\n",
    "# Creating the image dictionary where the key is the image name and the image index \n",
    "image_dict = dict()\n",
    "for image in images:\n",
    "    image_dict[image] = int(image.split('.')[0])\n",
    "\n",
    "# Sorting the images by the index\n",
    "images = sorted(images, key=lambda x: image_dict[x])\n",
    "\n",
    "# Defining the output video path\n",
    "output_video_path = os.path.join(os.getcwd(), 'output_video.mp4')\n",
    "\n",
    "# Defining the fps\n",
    "fps = 24\n",
    "\n",
    "# Defining the size of the video\n",
    "# Reading the first image to get the sizes \n",
    "img = cv2.imread(os.path.join(postprocessed_images_dir, images[0]))\n",
    "size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Defining the video writer\n",
    "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "\n",
    "# Iterating over the images\n",
    "for image in tqdm(images):\n",
    "    # Reading the image\n",
    "    img = cv2.imread(os.path.join(postprocessed_images_dir, image))\n",
    "\n",
    "    # Writing the image\n",
    "    out.write(img)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Closing the video writer\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waldo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
